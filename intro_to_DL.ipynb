{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cd7ca66-98d2-472f-8c24-d91d0bbce331",
   "metadata": {},
   "source": [
    "## \"Hello World\" in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b6c2d-d0c6-46a0-807b-fedea3117e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports torch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Defines our first network\n",
    "class FirstNetwork(nn.Module):\n",
    "    def __init__(self, multiplier):\n",
    "        super().__init__()\n",
    "        self.multiplier = nn.Parameter(torch.tensor(float(multiplier)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.multiplier * x\n",
    "\n",
    "# Initializes FirstNetwork\n",
    "network = FirstNetwork(2)\n",
    "print(network)\n",
    "\n",
    "# Runs the network on an input and gets the result\n",
    "network(4).item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5267fd0-296a-4bb4-b8bb-69404130f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a logistic regression model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_features, class_num):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Linear(input_features, class_num)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.weights(x)\n",
    "    \n",
    "    def get_probabilities(self, x):\n",
    "        p = nn.functional.softmax(self(x), dim=-1)\n",
    "        return p.detach().numpy()\n",
    "\n",
    "# Initializes LogisticRegression with 3 features and 2 classes\n",
    "lr_network = LogisticRegression(3, 2)\n",
    "print(lr_network)\n",
    "\n",
    "# Defines some fake data for testing\n",
    "# 2 examples with 3 features each\n",
    "test_data = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                         [3.0, 2.0, 1.0]])\n",
    "print(test_data)\n",
    "\n",
    "# Gets the probabilities for each example for each class\n",
    "lr_network.get_probabilities(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f63ce-11d2-4be9-8461-351f69fba20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Defines some fake labels for the fake data\n",
    "test_labels = torch.tensor([0, 1])\n",
    "\n",
    "# Calls the network on the test data (using forward)\n",
    "output = lr_network(test_data)\n",
    "\n",
    "# Checks the shape of the output and labels\n",
    "# (Just for debugging)\n",
    "print(output.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "# Computes the average loss over examples\n",
    "loss_func(output, test_labels).item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af666367-e19a-4b50-96bc-303aa063d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines some random train and test data, where the positive class has\n",
    "# higher average value for the first feature\n",
    "# \n",
    "# Don't worry too much about this code\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "X_train = default_rng(0).standard_normal([100, 3])\n",
    "X_test = default_rng(1).standard_normal([100, 3])\n",
    "for i in range(50):\n",
    "    X_train[i, 0] += 1.5\n",
    "    X_test[i, 0] += 1.5\n",
    "Y_train = np.concatenate([np.ones(50), np.zeros(50)])\n",
    "Y_test = np.concatenate([np.ones(50), np.zeros(50)])\n",
    "\n",
    "print(np.mean(X_train[:50],axis=0))\n",
    "print(np.mean(X_train[50:],axis=0))\n",
    "print()\n",
    "print(Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0eaee-4a75-47a2-b859-c1343eac66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wraps the data in PyTorch datasets\n",
    "from torch.utils.data import TensorDataset\n",
    "dataset_train = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                              torch.tensor(Y_train, dtype=torch.long))\n",
    "\n",
    "dataset_test = TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                             torch.tensor(Y_test, dtype=torch.long))\n",
    "\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_test))\n",
    "\n",
    "# Creates data loaders to batch up the data\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=10, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=10, shuffle=False)\n",
    "\n",
    "for X, Y in dataloader_train:\n",
    "    print(X)\n",
    "    print(Y)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b540f4-61e4-4c61-b5f2-9fb37328708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an optimizer\n",
    "from torch.optim import SGD\n",
    "lr_optimizer = SGD(lr_network.parameters(), lr=0.01)\n",
    "print(lr_optimizer)\n",
    "\n",
    "# Iteratively minimizes training loss\n",
    "epochs = 500\n",
    "lr_network.train()\n",
    "\n",
    "for _ in range(epochs):\n",
    "    for X, Y in dataloader_train:\n",
    "        # Zeros out gradient information\n",
    "        lr_optimizer.zero_grad()\n",
    "        \n",
    "        # Computes the training loss on the batch\n",
    "        outputs = lr_network(X)\n",
    "        loss = loss_func(outputs, Y)\n",
    "        \n",
    "        # Computes gradient\n",
    "        loss.backward()\n",
    "        \n",
    "        # Takes optimization step\n",
    "        lr_optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755d241-1daf-4371-a36a-124cb0c95b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes test loss\n",
    "lr_test_loss = 0\n",
    "lr_network.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, Y in dataloader_test:\n",
    "        # Computes the training loss on the batch\n",
    "            outputs = lr_network(X)\n",
    "            loss = loss_func(outputs, Y)\n",
    "\n",
    "            lr_test_loss += loss.item() * X.shape[0]\n",
    "\n",
    "print(lr_test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa7fa8-4afd-4301-ba2c-6cb8a9d4cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a multilayer perceptron model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_features, hidden_size, class_num):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_features, hidden_size)\n",
    "        self.activation1 = nn.Sigmoid()\n",
    "        self.layer2 = nn.Linear(hidden_size, class_num)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.activation1(out)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "    \n",
    "    def get_probabilities(self, x):\n",
    "        p = nn.functional.softmax(self(x), dim=-1)\n",
    "        return p.detach().numpy()\n",
    "\n",
    "# Initializes MLP with 3 features, 10 hidden units, and 2 classes\n",
    "mlp_network = MLP(3, 10, 2)\n",
    "print(mlp_network)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77313cd0-5489-4996-99f1-fb67176e5b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the MLP\n",
    "mlp_optimizer = SGD(mlp_network.parameters(), lr=0.01)\n",
    "mlp_network.train()\n",
    "\n",
    "for _ in range(epochs):\n",
    "    for X, Y in dataloader_train:\n",
    "        # Zeros out gradient information\n",
    "        mlp_optimizer.zero_grad()\n",
    "        \n",
    "        # Computes the training loss on the batch\n",
    "        outputs = mlp_network(X)\n",
    "        loss = loss_func(outputs, Y)\n",
    "        \n",
    "        # Computes gradient\n",
    "        loss.backward()\n",
    "        \n",
    "        # Takes optimization step\n",
    "        mlp_optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ef95c-207c-448c-8fd7-7d8f39b7f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes test loss for MLP\n",
    "mlp_test_loss = 0\n",
    "mlp_network.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, Y in dataloader_test:\n",
    "        # Computes the loss on the batch\n",
    "        outputs = mlp_network(X)\n",
    "        loss = loss_func(outputs, Y)\n",
    "        \n",
    "        mlp_test_loss += loss.item() * X.shape[0]\n",
    "\n",
    "print(mlp_test_loss)\n",
    "\n",
    "if mlp_test_loss < lr_test_loss:\n",
    "    print(\"MLP has lower test loss!\")\n",
    "else:\n",
    "    print(\"LogisticRegression has lower test loss!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da55e3a0-01d4-48e3-b164-f71e1b8feb98",
   "metadata": {},
   "source": [
    "## Let's go back to Lecture 18, slide 12!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826cc55d-7d52-41ae-bde1-b88a8b2a046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines an input tensor of 10 x 10 \"images\" with 2 examples 3 color channels\n",
    "color_channels = 3\n",
    "imgs = default_rng(2).standard_normal([2, color_channels, 10, 10])\n",
    "imgs = torch.tensor(imgs, dtype=torch.float32)\n",
    "\n",
    "# Defines some 2d convolutional layers and compares the shapes of the outputs\n",
    "out_channels = 1\n",
    "kernel_size = 1\n",
    "stride = 1\n",
    "\n",
    "conv = nn.Conv2d(\n",
    "    color_channels, out_channels, kernel_size=kernel_size, stride=stride\n",
    ")\n",
    "print(conv)\n",
    "print(conv(imgs).shape)\n",
    "\n",
    "# Flattens the output so that we can treat features as a vector\n",
    "flatten = nn.Flatten()\n",
    "print(flatten(conv(imgs)).shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee87855-5594-4d6f-aea0-175b76574fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
